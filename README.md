# WordWebDB_API

WordWebDB_API is a Flask-based API that acts as an intermediary for a PostgreSQL database. It is designed to manage and interact with the WordWebDB, a database for storing phrases, definitions of words, and tracking the frequency of word encounters. It also keeps track of video clips, pages, and visual explorations related to the words being learned. Optionally, also Anki card ids and decks.

Words and phrases and definitions can be manually entered into it from dictionaries and native media, etc. However, this API is designed with the intent of using Generative AI to automatically create enumerated dictionary entries and example sentences for each new word the learner encounteres in native media so that the learner doesn't have to look up words in a dictionary. 

It will work alongside the `AnkiAPI` to automatically generate flashcards and keep track of card ids that contain the word. 

It is intended to work with other applications as well so `object exploration` is an optional field because the learner will have the opportunity to explor objects using generative ai, to generate images, audio, and text to learn more about the object in the target language. These can be turned on or off upon initialization. 

`Story Name` is also an optional field. This database will be integrated with an app that will consolidate words that were encountered in an immersive session in the target language and a story will be generated that contains the words to help consolidate the learning. 

The `Media Excerpts` will feature either video clips or excerpts from stories, or audio, that contain the word in question. 

The `Familiar` field keeps track of whether or not the word has been encountered in an Anki Card if Anki is integrated, and if Anki isn't, whether or not it has been encountered in native media. The reason this is necessary is because the generative AI will be generating definitions for every single word that are needed to understand every single word in the phrase the learner encountered as well as every single word in the definition. The words in the definition may not have been encountered in native media. The words that were generated by the AI but not encountered in Native Media will have `False` for familiar until this word has been encountered in an Anki Card. 

## Features

- Initialize the database from scratch
- Prepare the database for use in applications
- CRUD operations for phrases and definitions
- Track frequency of word encounters
- Manage video clips and pages related to words
- Handle visual explorations of words
- Database of lemmas
  -  each lemma is mapped to its enumerated definitions contained inside of the Database of enumerated definitions
- Database of enumerated definitions
  - Each of the most frequent definitions as defined and determined by the generative AI or in accordance with which definitions were manually supplied by the learner for the lemma inside the Lemmas database are labeled with the name of the lemma plus a subscript from 1 to n.
  - i.e. 
    - <strong>lemma</strong>: super, 
    - <strong>enumerated definitions</strong>: 
      - super<sub>1</sub>: adj; means excellent or very good. 
      - super<sub>2</sub>: adv; to an extreme degree or extremely. 
      - super<sub>3</sub>: prefix; above, over, or beyond.

## Database Schema

### Database of Lemmas

| Lemma | List of Lemma Enumerations | Frequency |
|-------|---------------------------|-----------|
|       |                           |           |

### Database of Enumerated Lemmas

| Enumerated Lemma | Part of Speech | Definition | Example Phrase | Frequency | Story Name | Media Excerpts | Object Exploration Link | Anki Card Ids | Familiar |
|------------------|----------------|------------|----------------|-----------|------------|----------------|-------------------------|---------------|----------|
|                  |                |            |                |           |            |                |                         |               |          |

## Getting Started

### Prerequisites

- docker-engine

## Docker Deployment

WordWebDB_API is designed to be deployed using Docker, which ensures that it runs in the same environment regardless of where it is deployed. The Docker container also includes a PostgreSQL database, providing a self-contained environment for the application.

1. Clone the repository
    ```
    git clone https://github.com/yourusername/WordWebDB_API.git
    ```
2. Navigate to the project directory
    ```
    cd WordWebDB_API
    ```

### Building the Docker Image

1. Ensure Docker is installed on your machine.
2. Navigate to the project directory.
3. Build the Docker image:
    ```
    docker build -t wordwebdb_api .
    ```

### Running the Docker Container

1. Run the Docker container:
    ```
    docker run -p 5000:5000 wordwebdb_api
    ```

Now, WordWebDB_API is running in a Docker container on your machine, accessible at `localhost:5000`.

### Running the API

1. Run the Flask app
    ```
    flask run
    ```

## API Endpoints

- `/init_db`: Initializes the database from scratch
- `/prepare_db`: Prepares the database for use in applications
- `/words`: CRUD operations for phrases and definitions
- `/encounters`: Track frequency of word encounters
- `/media`: Manage video clips and pages related to words
- `/explorations`: Handle visual explorations of words

## Contributing

Please read [CONTRIBUTING.md](https://github.com/yourusername/WordWebDB_API/blob/main/CONTRIBUTING.md) for details on our code of conduct, and the process for submitting pull requests to us.

## License

This project is licensed under the MIT License - see the [LICENSE.md](https://github.com/yourusername/WordWebDB_API/blob/main/LICENSE.md) file for details.